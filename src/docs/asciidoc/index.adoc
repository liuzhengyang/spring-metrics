:github-tag: master
:github-repo: spring-projects/spring-metrics
:github-raw: http://raw.github.com/{github-repo}/{github-tag}
:github-code: http://github.com/{github-repo}/tree/{github-tag}
:all: {asterisk}{asterisk}
:nofooter:
:imagesdir: ./images
= Spring Metrics

image:https://circleci.com/gh/spring-projects/spring-metrics.svg?style=svg[Build Status, link=https://circleci.com/gh/spring-cloud/spring-metrics]
image:https://badges.gitter.im/Join%20Chat.svg[Gitter, link="https://gitter.im/spring-projects/spring-metrics?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge"]
image:https://img.shields.io/badge/License-Apache%202.0-blue.svg[Apache License,link="http://www.apache.org/licenses/LICENSE-2.0"]

This project provides facilities for instrumenting apps with metrics collection
and interacting with popular third-party application monitoring systems.

== Installing

Pre-release artifacts are being published frequently, but are NOT intended for production use.

In Gradle:

```groovy
compile 'org.springframework.metrics:spring-metrics:latest.release'
```

Or in Maven:

```xml
<dependency>
  <groupId>org.springframework.metrics</groupId>
  <artifactId>spring-metrics</artifactId>
  <version>${metrics.version}</version>
</dependency>
```

== Instrumentation

Spring Metrics features a metrics collection API that is designed to record dimensional
time series for export to a variety of time series databases and monitoring backends.

Suppose we have a simple service and we want to keep track of:

* Number of requests received with dimensions for breaking down by status code, method, the exception type if the request fails in an unexpected way, etc.
* Latency for handling requests.
* The size of a collection that is acting as a cache.

Here is an example of what this might look like with `spring-metrics`.

```java
@RestController
@Timed
public class MyController {
    Map<Integer, Person> people = new Map<Integer, Person>();

    public MyController(MeterRegistry registry) {
        // constructs a gauge to monitor the size of the population
        registry.mapSize("population", people);
    }

    @GetMapping("/api/people")
    public List<Person> listPeople() {
        return people;
    }

    @GetMapping("/api/person/{id}")
    public Person findPerson(@PathVariable Integer id) {
        return people.get(id);
    }
}
```

In this sample code, multiple dimensional time series are created with a variety of metrics:

1. Adding `@Timed` to the controller creates a `Timer` time series named `http-requests` which
by default contains dimensions for the HTTP status of the response, HTTP method, exception type if the request fails,
and the pre-variable substitution parameterized endpoint URI.
2. Calling `collectionSize` on our meter registry adds a `Gauge` time series named `population` that
changes when observed by a metrics backend or exporter.

Let's break down the key pieces of the instrumentation API in detail.

=== Meter

A meter is the interface for collecting a set of measurements (which we individually call metrics) about your application. `spring-metrics`
packs with a supported set of `Meter` primitives including: `Timer`, `Counter`, `Gauge`, `DistributionSummary`,
and `LongTaskTimer`. Note that different meter types result in a different number of metrics. For example, while there is a single
metric that represents a `Gauge`, a `Timer` measures both number of timed events and the total time of all events timed.

=== Meter Registry

A registry creates and manages your application's set of meters. Exporters use the meter registry to iterate
over the set of meters instrumenting your application, and then further iterate over each meter's metrics, generally
resulting in a time series in the metrics backend for each combination of metrics and dimensions.

Two meter registry implementations are provided out-of-the-box: `SpectatorMeterRegistry` and `PrometheusMeterRegistry`. Add one
or the other to your application context:

```java
@Bean
public MeterRegistry meterRegistry() { return new PrometheusMeterRegistry(); }
```

Then, inject the `MeterRegistry` elsewhere to create meters that you can use to instrument your app:

```java
@RestController
public class MyController {
    List<Person> people = new ArrayList<Person>();
    Counter steveCounter;
    Timer findPersonTimer;

    public MyController(MeterRegistry registry) {
        // registers a gauge to observe the size of the population
        registry.collectionSize("population", people);

        // register a counter of questionable usefulness
        steveCounter = registry.counter("find_steve", /* optional tags here */);

        // register a timer -- though for request timing it is easier to use @Timed
        findPersonTimer = registry.timer("http_requests", "method", "GET");
    }

    @GetMapping("/api/person")
    public Person findPerson(@RequestParam String q) {
        return findPersonTimer.record(() -> { // use the timer!
            if(q.toLowerCase().contains("steve")) {
                steveCounter.increment(); // use the counter
            }

            return people.stream().filter(p -> /* etc */).findAny().orElse(null);
        });
    }
}
```

=== Dimensions/Tags

A meter is uniquely identified by its name and dimensions. We use the term dimensions and tags interchangeably, and
the `spring-metrics` interface is `Tag` simply because it is shorter.

As a general rule it should be possible to use the name as a pivot. Dimensions allow a particular named metric
to be sliced to drill down and reason about the data. This means that if just the name is selected, then the user can drill down
using other dimensions and be able to reason about the value being shown.

Suppose we are trying to measure the number of threads in a thread pool and the number of rows in a database table.

==== Recommended approach

```java
registry.counter("threadpool-size", "id", "server-requests")
registry.counter("db-size", "table", "users")
```

This variant provides enough context so that if just the name is selected the value can be reasoned about and
is at least potentially meaningful. For example if we select `threadpool.size` we can see the total number of
threads in all pools. Then we can group by or select an `id` to drill down further or perform comparative
analysis on the contribution of each functional area to the number of threads consumed by the instrumented app.

[NOTE]
====
We do not offer an opinion about naming styles. Spectator promotes camel case and Prometheus promotes '_' separation
(along with other https://prometheus.io/docs/practices/naming/#metric-names[recommendations]),
but they are both are admittedly arbitrary. Consistency is key. We recommend following the convention most commonly used by your
organization or your chosen metrics backend. It is recommended to stay away from '-' separated names, as some metrics
backends interpret '-' as metric subtraction.
====

==== Bad approach

```java
registry.counter("size",
    "class", "ThreadPool",
    "id", "server-requests");

registry.counter("size",
    "class", "Database",
    "table", "users");
```

In this approach, if we select `size` we will get a value that is an aggregate of the number of threads
and the number of items in a database. This time series is not useful without further dimensional drill-down.

=== Measuring in Base Units

Keep measurements in base units where possible. For example, disk sizes should be bytes, or network rates should
be in bytes/second. The unit should be obvious from the name. It also means the SI prefix shown on graph images
make more sense, e.g. 1k is 1 kilobyte not 1 kilo-megabyte.

The appropriate base unit for timers does vary by metrics backend for good reason. We will discuss this further
in the Timers section.

=== Counters

Counters report a single metric, a count. The `Counter` interface allows you to increment by a fixed amount, and isn't
opinionated about whether that fixed amount may be negative.

[CAUTION]
====
Prometheus is opinionated about decrementing counters, and will throw an exception if you attempt to decrement. Other
systems have no such strictures. For the vast majority of counter uses, decrementing is not a requirement anyway.
====

When building graphs and alerts off of counters, generally you should be most interested in measuring the rate at
which some event is occurring over a given time interval. Consider a simple queue, counters could be used to measure
things like the rate at which items are being inserted and removed.

It's tempting at first to conceive of visualizing absolute counts rather than a rate, but carefully consider that
the absolute count is usually both a function of the rapidity with which something is used *and* the longevity of the
application instance under instrumentation. Building dashboards and alerts of the rate of a counter per some interval of
time disregards the longevity of the app. This knowledge is built-into some metrics backends like Atlas, which only
consume the rate from counters.

=== Timers

Timers are useful for measuring short-duration latencies and the frequency of such events. They report the total time
and count of events as two separate metrics.

As an example, consider a chart showing request latency to a typical web server. The expectation is many short requests
so the timer will be getting updated many times per second.

.Request Latency
image::request-latency.png[]

The appropriate base unit for timers does vary by metrics backend for good reason.
Prometheus recommends recording timings in seconds (as this is technically a base unit),
but records this value as a `double`. Spectator records timings with a `long`, and so is
biased to maintaining a base unit of nanoseconds. `spring-metrics` is decidedly un-opinionated
about this, but because of the potential for confusion, requires a `TimeUnit` when interacting
with `Timers`. `spring-metrics` is aware of the preferences of each implementation and stores your
timing in the appropriate base unit based on the implementation.

```java
public interface Timer extends Meter {
    void record(long amount, TimeUnit unit);
    double totalTime(TimeUnit unit);
}
```

[NOTE]
====
While reading directly from a `spring-metrics` timer returns a `double`,
the underlying value stored in a Spectator-like implementation may be a nanosecond precise
`long`. What precision is lost by converting to a `double` in the `spring-metrics`
interface will not affect a system like Atlas, because it will be configured to read measurements
from the underlying Spectator Timer that `spring-metrics` is hiding from you.
====

=== Long Task Timers

The long task timer is a special type of timer that allows you to measure time while an
event being measured is *still running*. A timer does not record the duration
and until the task is complete.

Now consider a background process to refresh metadata from a data store.
For example, Edda caches AWS resources such as instances, volumes, auto-scaling
groups etc. Normally all data can be refreshed in a few minutes. If the AWS
services are having problems it can take much longer. A long duration timer can
be used to track the overall time for refreshing the metadata.

In a Spring application, it is common for such long running processes to be implemented with `@Scheduled`.
`spring-metrics` provides a special `@Timed` annotation for instrumenting these processes with a long
task timer:

```java
@Timed(value = "aws_scrape", longTask = true)
@Scheduled(fixedDelay = 360000)
void scrapeResources() {
    // find instances, volumes, auto-scaling groups, etc...
}
```

The charts below show max latency for the refresh using a regular timer and a
long task timer. Regular timer, note that the y-axis is using a logarithmic scale:

.Regular Timer
image::long-duration-regular-timer.png[]

With the long task timer:

.Long Task Timer
image::long-duration-timer.png[]

If we wanted to alert when this process exceeds `threshold`,
with a long task timer we will receive that alert at the first
reporting interval after we have exceeded the threshold. With a regular
timer, we wouldn't receive the alert until the first reporting interval after
the process completed, over an hour later!

=== Gauges

A gauge is a handle to get the current value. Typical examples for gauges
would be the size of a collection or map or number of threads in a running state.

`spring-metrics` takes the stance that gauges should be sampled and not set, so
there is no information about what might have occurred between samples. After all,
any intermediate values set on a gauge are lost by the time the gauge value is reported
to a metrics backend anyway, so there seems to be little value in setting those intermediate
values in the first place.

If it helps, think of a `Gauge` as a heisengauge - a meter that only changes when it
is observed.

[NOTE]
====
In Prometheus, a gauge is a generalization of a counter that also happens to allow
for decrementing. If you view a gauge as something that is actively set by the application
application code rather than sampled, it is clear that your code would have to increment
and decrement the gauge as the size of the thing being measured changes. We do not believe
this view is without merit, but rather is practically equivalent to the heisengauge from the
results in the monitoring system but harder to work with in code.
====

The `MeterRegistry` interface contains a number of convenience methods for instrumenting
collections, maps, executors, and caches with gauges.

Lastly, Gauges are useful for monitoring things with natural upper bounds. We don't recommend
using a gauge to monitor things like request count, as they can grow without bound for
the duration of an application instance's life.

=== Distribution Summary

A distribution summary is used to track the distribution of events. It is wholly
similar to a timer, but more general in that the size does not have to be a period of
time. For example, a distribution summary could be used to measure the payload
sizes of requests hitting a server.

=== Quantile Statistics

Timers and distribution summaries can be enriched with https://en.wikipedia.org/wiki/Quantile[quantiles] computed in your app prior to shipping
to a monitoring backend.

```java
Timer timer = meterRegistry.timerBuilder("my_timer")
                .quantiles(WindowSketchQuantiles.quantiles(0.5, 0.95).create())
                .create();
```

For distribution summaries, you can use `summaryBuilder(name)` which mirrors this construction.

This would result in additional gauges with tags `quantile=0.5` and `quantile=0.95`. The 0.95 quantile is the
the value below which 95% of observations in a group of observations fall. 0.5 represents the media of our
observations thus far.

Four quantile algorithms are provided out of the box with different tradeoffs:

* `WindowSketchQuantiles` - The importance of an observation is decayed as it ages. This is the most computationally
costly algorithm.

```java
WindowSketchQuantiles.quantiles(0.5, 0.95)
    .error(0.01) // OPTIONAL, defaults to 0.05
    .create()
```

* `Frugal2UQuantiles` - Successive approximation algorithm that converges towards the true quantile with enough
observations. This is by least costly algorithm, but exhibits a higher error ratio in early observations.

```java
Frugal2UQuantiles
    // the closer the initial estimate (100) is to the true quantile, the faster it converges
    .quantile(0.95, 100)
    .quantile(0.5, 150)
    .create()
```

* `CKMSQuantiles` - Allows you to tradeoff computational complexity for error ratio on a per quantile basis. Often,
it is desirable for higher quantiles to have a lower error ratio (e.g. 0.99 at 1% error vs. 0.5 at 5% error). Still
more computationally expensive than Frugal.

```java
CKMSQuantiles
    .quantile(0.95, 0.01)
    .quantile(0.5, 0.05)
    .create()
```

* `GKQuantiles` - Allows you to tradeoff computational complexity for error ratio across all quantiles. This is
used inside of `WindowSketchQuantiles`.

```java
GKQuantiles.quantiles(0.5, 0.95)
    .error(0.01) // OPTIONAL, defaults to 0.05
    .create()
```

Here is a demonstration of all four algorithms operating simultaneously on the same distribution:

.Quantile Algorithms at Work
image::quantile-algorithms.png[]

It is also possible to indicate that you want to compute quantiles in an `@Timed` annotation:

```java
@RestController
public class MyController {
    @Timed(value = "list_people", quantiles = {0.5, 0.95})
    @GetMapping("/api/people")
    public List<Person> listPeople() { ... }
```

=== Histogram Statistics

Timers and distribution summaries can be enriched with histogram statistics that yield a counter
time series for each of a set of buckets.

Histograms can be used to compute quantiles or other summary statistics in some monitoring backends
(e.g. https://prometheus.io/docs/querying/functions/#histogram_quantile[Prometheus]). Because histograms
buckets are exposed as individual counters to the monitoring backend, it is possible to aggregate
observations across a distributed system and compute summary statistics like quantiles for an entire
cluster.

Naturally, the error rate of the computed summary statistic will be higher because of the lossy nature of bucketing data.

`spring-metrics` supports both cumulative and non-cumulative (normal) histograms and provides a set of
generators for each.

```java
DistributionSummary hist = meterRegistry.summaryBuilder("hist")
        .histogram(CumulativeHistogram.buckets(linear(0, 10, 20)))
        .create();
```

For timers, you can use `timerBuilder(name)` which mirrors this construction.

This sample constructs a cumulative histogram consisting of 20 buckets, one every 10 units
beginning at 0.

To construct a normal histogram, use the generators on `NormalHistogram`.

For timers, be sure to specify the `TimeUnit` that your buckets represent. The bucket tag value
on the time series will be normalized to the expected time base unit of the monitoring backend
(e.g. seconds on Prometheus, nanoseconds on Atlas). In this way, you can keep your histograms
backend agnostic.

```java
CumulativeHistogram.buckets(linear(0, 10, 20), TimeUnit.MILLISECONDS);
```

=== Cache Monitoring

Guava caches can be instrumented with the registry, but it is important that you call `recordStats()` on
the `CacheBuilder`, as it is not possible to turn this on after the `Cache` is constructed.

```java
@Repository
class PersonRepository {
    LoadingCache<String, Person> personBySsn;

    public PersonRepository(MeterRegistry registry) {
        personBySsn = Meters.monitor(registry, CacheBuilder.newBuilder().recordStats().build(),
            "people_cache", // base metric name
            "lookup_key", "ssn" // <- any number of tag key/value pairs
        );
    }
}
```

Cache instrumentation results in several gauges whose names are
prefixed by the provided name ("people_cache" in this example),
corresponding to the stats recorded in `CacheStats`.

The original cache instance is unchanged by instrumentation.

=== Data Source Monitoring

Data sources can be instrumented with the registry. This requires
the `DataSourcePoolMetadataProvider` automatically configured by Spring
Boot, so only works in a Spring Boot context where these providers
are configured.

```java
@Configuration
class MyConfiguration {
    @Autowired
    private DataSource dataSource;

    @Autowired
    private Collection<DataSourcePoolMetadataProvider> metadataProviders;

    @Autowired
    private Environment env;

    @PostConstruct
    private void instrumentDataSource() {
        Meters.monitor(
            registry,
            dataSource,
            metadataProviders,
            "data_source", // base metric name
            "stack", env.acceptsProfiles("prod") ? "prod" : "test", // <- any number of tags
        );
    }
}
```

Data source instrumentation results in gauges representing the
currently active, maximum allowed, and minimum allowed connections
in the pool. Each of these gauges has a name which is prefixed by
the provided name ("data_source" in this example).

The original data source instance is unchanged by instrumentation.

=== Executor and ExecutorService Monitoring

`Executor` and `ExecutorService` instances can be instrumented with the registry. This includes any
specializations of these types created by `java.util.concurrent.Executors`. Additionally, you can
directly monitor `ThreadPoolTaskExecutor` and `ThreadPoolTaskScheduler` in a wholly similar way, but
they must be initialized prior to attempting to instrument them.

```java
@Configuration
class MyConfiguration {
    @Bean("worker_pool")
    ExecutorService workerPool(MeterRegistry registry) {
        return Meters.monitor(registry,
            Executors.newFixedThreadPool(8),
            "worker_pool",
            "threads", "8" // any number of tag key value pairs
        );
    }
}
```

`ExecutorService` instrumentation results in a composite counter that tracks
 the number of submitted, active, and completed tasks. Additionally, a timer records the
 execution time of tasks (plus a count of such tasks, since `Timer`s always track both count
 and totalTime statistics).

`Executor` instrumentation just records the execution time.

=== Meter Binders

Meter binders register one or more metrics to provide information about the state of some aspect
of the application or its container.

To enable the collection of the set of metrics encapsulated in a binder, define the binder as a bean:

```java
@Bean
JvmMemoryMetrics memoryBinder() {
    return new JvmMemoryMetrics();
}
```

This will bind metrics to all `MeterRegistry` instances in the application context. To manually
bind metrics to a single `MeterRegistry`:

```java
@Bean
MeterRegistry prometheusRegistry() {
    MeterRegistry registry = new PrometheusMeterRegistry();
    new JvmMemoryMetrics().bindTo(registry);
    return registry;
}
```

Any meter binder that is registered separately as a `@Bean` will be injected into `MeterRegistry` implementations
provided by `spring-metrics`:

```java
@Bean
JvmMemoryMetrics memoryMetrics() { return new JvmMemoryMetrics(); }
```

Binders are enabled by default via Spring Boot auto configuration if they source data for an alert
that is recommended for a production ready app. The idea is to encourage the capture of metrics
that are the most actionable. The following binders are auto-configured:

1. `JvmGcMetrics` - Records information about GC events and their causes, split by generation.
We recommend setting up alerts for production ready apps for (1) if `jvm_gc_pause` exceeds some fixed value (500 ms
is a good general purpose value) and (2) if `jvm_gc_live_data_size` exceeds 70% of the heap.
2. `LogbackMetrics` - Records counts for log event at various levels. Auto-configured in the presence of `logback-core`.

== Server-side HTTP Instrumentation

`spring-metrics` contains built-in instrumentation for timings of requests made
to Spring MVC and Spring WebFlux server endpoints.

=== Web MVC and Annotation-Based WebFlux

Adding `@EnableMetrics` to your `@SpringBootApplication` class autoconfigures these
interceptors.

The interceptors need to be enabled for every request handler or controller that you want
to time. Add `@Timed` to:

1. A controller class to enable timings on every request handler in the controller.
2. A method to enable for an individual endpoint. This is not necessary if you have it on the class.
3. A method with `longTask = true` to enable a long task timer for the method. Long task timers require a
separate metric name, and can be stacked with a short task timer.

```java
@RestController
@Timed // (1)
public class MyController {
    @GetMapping("/api/people")
    @Timed // (2)
    @Timed(value = "all_people", longTask = true) // (3)
    public List<Person> listPeople() { ... }
```

The `Timer` is registered with a name of `http_server_requests` by default. This can be changed by setting
`spring.metrics.web.server_requests.name`.

The `Timer` contains a set of dimensions for every request, governed by the primary bean `WebfluxTagConfigurer` or
`WebmvcTagConfigurer` (depending on which programming model you are using) registered in your application
context. If you don't provide such a bean, a default implementation is selected which adds the following dimensions:

1. `method`, the HTTP method (e.g. GET, PUT)
2. `status`, the numeric HTTP status code (e.g. 200, 201, 500)
3. `uri`, the URI template prior to variable substitution (e.g. /api/person/{id})
4. `exception`, the simple name of the exception class thrown (only if an exception is thrown)

In addition to the default tags provided, you can add fixed tags to individual
controllers or request methods via the `extraTags` attribute on `@Timed`:

```java
@Timed(extraTags = {"authenticated", "false"})
```

=== Webflux Functional

`spring-metrics` contains a filter that you can add to a `RouterFunction` to instrument timings to its routes.

```java
RouterFunctionMetrics metrics = new RouterFunctionMetrics(registry);

// OPTIONAL: the default is to record tags on method and status
metrics.defaultTags((req, resp) -> { /* custom tags here */ });

RouterFunction<ServerResponse> routes = RouterFunctions
    .route(GET("/person/{id}").and(accept(APPLICATION_JSON)),
        request -> ServerResponse.ok().build())
    .filter(metrics.timer(
        "http_server_requests", // metric name
        "instance", MY_INSTANCE_ID // optional tags
    ));
```

The filter applies to all routes defined by this router function.

== Client-side HTTP Instrumentation

Adding `@EnableMetrics` to your `@SpringBootApplication` class configures a `BeanPostProcessor` for `RestTemplate`,
so every instance you create via the application context will be instrumented.

A timer is recorded for each invocation that includes tags for URI (before parameter substitution), host, and status.
The name of this timer is `http_client_requests`, and can be changed via the `spring.metrics.web.client_requests.name`
property.

== Scheduling Instrumentation

Adding `@EnableMetrics` to your `@SpringBootApplication` class plus enabling AOP configures AOP advice that times
`@Scheduled` methods. For a method to be timed, it must be marked as `@Timed("my_metric_name")` with a name.

Depending on the duration of the scheduled task, you may want to choose to time the method with a `LongTaskTimer`,
a `Timer`, or both. Below is an example of measuring both long task and regular timings to a scheduled task:

```java
@Timed("beep")
@Timed(value = "long_beep", longTask = true)
@Scheduled(fixedRate = 1000)
void longBeep() {
    // calculate the meaning of life, then beep...
    System.out.println("beep");
}
```

== Prometheus

=== Quickstart for Prometheus-based monitoring

You will need the following dependencies:

```groovy
compile 'org.springframework.metrics:spring-metrics:latest.release'
compile 'io.prometheus:simpleclient_common:latest.release'
```

Add `@EnablePrometheusMetrics` to your configuration.

```java
@SpringBootApplication
@EnablePrometheusMetrics
public class MyApp {
}
```

Then inject `MeterRegistry` wherever you need to create a timer, gauge, counter, or summary.

=== Pulling metrics with scraping

`@EnablePrometheusMetrics` also applies `@EnablePrometheusScraping` to your Spring Boot application which
enables a Spring Boot Actuator endpoint at `/prometheus` that presents a Prometheus
scrape with the appropriate format.

A router function generator is also provided to add a scraping endpoint to a Webflux functional application:

```java
PrometheusMeterRegistry meterRegistry = new PrometheusMeterRegistry();
RouterFunction<ServerResponse> route = route(GET("/prometheus"),
    PrometheusFunctions.scrape(meterRegistry));
```

Here is an example `scrape_config` to add to prometheus.yml:

```yml
scrape_configs:
  - job_name: 'spring'
    metrics_path: '/prometheus'
    static_configs:
      - targets: ['HOST:PORT']
```

== Netflix Atlas

=== Quickstart for Atlas-based monitoring

You will need the following dependencies:

```groovy
compile 'org.springframework.metrics:spring-metrics:latest.release'
compile 'com.netflix.spectator:spectator-reg-atlas:latest.release'
```

Add `@EnableAtlasMetrics` to your configuration.

```java
@SpringBootApplication
@EnableAtlasMetrics
public class MyApp {
}
```

Spectator's Atlas registry publishes metrics to an Atlas server periodically. Below is a list of
the most common configuration properties you will want to change and their default values
(from any property source, e.g. application.yml):

```yml
# The location of your Atlas server
atlas.uri: http://localhost:7101/api/v1/publish

# You will probably want disable Atlas publishing in a local development profile.
atlas.enabled: true

# The interval at which metrics are sent to Atlas. See Duration.parse for the expected format.
# The default is 1 minute.
atlas.step: PT1M
```

For a full list of configuration properties that can influence Atlas publishing, see
`com.netflix.spectator.atlas.AtlasConfig`.

Then inject `MeterRegistry` wherever you need to create a timer, gauge, counter, or summary.

== Dropwizard

=== A different meaning for the word "Meter"

We have adopted the definition of the term "meter" as initially described by Spectator. Those familiar with Dropwizard
metrics may recall that in Dropwizard a meter is a specialization of a counter that measures the rate of events over time
(e.g., “requests per second”). This is NOT the meaning of meter in `spring-metrics`.
